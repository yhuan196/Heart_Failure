---
title: '**Heart Failure Survival Study**'
author:
-  "Yi Huang, Runze Cui, Xuesen Zhao, Huanyu Chen, Jiahe Deng"
- 'P8108 Final Project Report: Group 6'
date: "Dec 10, 2023"
output:
  pdf_document:
    number_section: yes
    extra_dependencies: float
subtitle: '**Mailman School of Public Health at Columbia University**'
header-includes:
- \usepackage{caption}
- \usepackage{makecell}
- \captionsetup[figure]{labelformat=empty}
- \captionsetup[table]{labelformat=empty}
abstract: "Heart failure (HF) results from weakened heart muscles, impairing blood
  pumping and causing symptoms like breathlessness (Ahmad et al., 2017). Statistics
  show HF affects 1-2% of adults, especially those over 70, potentially higher due
  to misdiagnosis (Jones et al., 2019). HF prevalence increased by 25% since 2002
  due to aging, improved survival, and risk factors. This study utilizes data from
  the Institute of Cardiology and Allied Hospital in Faisalabad, Pakistan, which previously
  investigated the impact of key physiological and clinical factors on the prognosis
  of heart failure (HF) patients between April and December 2015. Our research employs
  a comprehensive range of statistical methodologies, including exploratory data analysis,
  nonparametric techniques, Kaplan-Meier curves, Cox proportional hazards models,
  and parametric survival models, aiming to identify significant predictors and investigate their influences on heart failure. The significant factors identified in our study include creatinine levels, age, ejection fraction, blood pressure, and serum sodium. Additionally, the model's discriminative ability across varied samples and conditions is validated using rigorous bootstrap validation methods such as c-index and calibration slope. Our findings contribute to refining risk assessment models, enhancing clinical decision-making, and optimizing patient care for heart failure in the future. The insights gained from our modeling process offer a deeper understanding of HF progression and its risk factors, paving the way for more personalized treatment approaches and preventive strategies that could profoundly impact patient outcomes and quality of life."
editor_options:
  chunk_output_type: console
---
\thispagestyle{empty}
\newpage
\tableofcontents
\thispagestyle{empty}
\newpage
\setcounter{page}{1}

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(biostat3)
library(tidyverse)
library(knitr)
library(kableExtra)
library(survival)
library(survminer)
library(ggfortify)
library(ggsurvfit)
library(patchwork)
library(writexl)
library(readxl)
library(table1)
library(rmarkdown)
library(KMsurv)
library(StepReg)
library(ggplot2)
library(timeROC)
library(boot)
library(rms)
library(survivalROC)
library(rpart)
library(eha)
library(pec)
```

# Introduction
## Background

Heart failure (HF) occurs when the muscles in the heart wall weaken and enlarge, impairing the heart's ability to pump blood effectively. This condition can cause the heart's ventricles to become stiff, hindering their ability to fill properly between beats. Over time, the heart becomes less capable of meeting the body's demand for blood, leading to symptoms like difficulty in breathing as the heart struggles to function efficiently.(Ahmad et al., 2017). 

According to the statistics, heart failure affects 1-2\% of adults in the general population and is more common in older individuals, with over 10\% of those aged over 70 years being diagnosed. The actual prevalence might be as high as 4\%, as heart failure is often undiagnosed or misdiagnosed, especially in the elderly. Since 2002, the prevalence of heart failure has increased by nearly 25\%, driven by factors such as an aging population, better survival rates post-coronary events, and a rise in risk factors like hypertension and atrial fibrillation. (Jones et al., 2019). 

## Objective

Our project aims to assess the influence of key physiological and clinical factors on the outcomes of heart failure patients at the Institute of Cardiology and Allied Hospital, Faisalabad, Pakistan, during April-December 2015. We will examine variables such as creatinine levels, gender, age, ejection fraction, blood pressure, anemia, and serum sodium to determine their impact on patient prognosis. Utilizing a range of analytic techniques including exploratory data analysis, nonparametric methods, hypothesis testing, semi-parametric modeling, parametric survival models, model checking, and validation procedures, our study is designed to identify crucial predictors of heart failure and to investigate their influences on the outcome. The insights gained from this analysis are expected to contribute significantly to the development of tailored treatment strategies and improved risk stratification models, thereby enhancing clinical decision-making and patient care for heart failure management.


# Exploratory Data Analysis (EDA)

The present study focuses on 299 heart failure patients, including 105 women and 194 men. All participants were over 40 years old and diagnosed with left ventricular systolic dysfunction, classified under NYHA classes III and IV. The follow-up duration ranged from 4 to 285 days, with an average of 130 days. Diagnosis of the disease was confirmed through cardiac echo-cardiogram reports or physician's notes. A brief description of variables in the dataset is shown below:

- **age**: Age in years 
- **time**: Survival time in days
- **event**: Event binary indicator (0 = Censored, 1 = Event)
- **gender**: Sex binary indicator (0 = Female, 1 = Male)
- **smoking**: Smoking status (0 = No smoking, 1 = Smoking)
- **diabetes**: Diabetes status (0 = No diabetes, 1 = Diabetes)
- **bp**: Blood pressure status (0 = Normal, 1 = Hypertension)
- **anemia**: Anemia status (0 = No anemia, 1 = Anemia: patients with haematocrit $<36$)
- **EF_cat**: Ejection fraction (Low: $\text{EF} \leq 30$, Medium: $30 < \text{EF} \leq 45$ and High: $\text{EF} >45$)
- **sodium**: Sodium in mEq/L
- **creatinine**: Serum creatinine in mg/dL 
- **platelets**: Platelets in mcL
- **cpk**: Creatinine phosphokinase in U/L

This study falls into the category of Overall Survival (OS), where event indicator equals 1 indicates the death of the subject and is the endpoint of survival. Specifically, 203 subjects were right-censored and 96 subjects have event. Detailed descriptive statistics table stratified by survival status are presented below. 

```{r}
data = read_csv("./data/heart_failure.csv") 
dat <- data |> 
  arrange(TIME) |> janitor::clean_names() |>
  mutate(ejection_fraction_cat = case_when(ejection_fraction <= 30 ~ "Low",
                                      ejection_fraction > 30
                                      & ejection_fraction <= 45 ~ "Medium",
                                      ejection_fraction > 45 ~ "High")) |> 
  mutate(gender = factor(gender), 
         smoking = factor(smoking),
         diabetes = factor(diabetes),
         bp = factor(bp),
         event = factor(event),
         anaemia = factor(anaemia),
         ejection_fraction_cat = factor(ejection_fraction_cat,
                                        levels = c("Low", "Medium", "High"))) |> 
  rename(platelets = pletelets,
         anemia = anaemia,
         EF = ejection_fraction,
         EF_cat = ejection_fraction_cat)

# Calculate the number of right-censored:
number_censored <- sum(dat$event == 0)
# Calculate the number of event:
number_event <- sum(dat$event == 1)
```


```{r results='asis'}
dat_table = dat
label(dat_table$time) = "Survival time (days)"
label(dat_table$gender) = "Gender"
label(dat_table$smoking) = "Smoking status"
label(dat_table$diabetes) = "Diabetes"
label(dat_table$bp) = "Blood Pressure"
label(dat_table$anemia) = "Anemia"
label(dat_table$age) = "Age (years)"
label(dat_table$EF_cat) = "Ejection Fraction (EF_cat)"
label(dat_table$sodium) = "Serum Sodium (mEq/L)"
label(dat_table$creatinine) = "Serum creatinine (mg/dL)"
label(dat_table$platelets) = "Plateletes (mcL)"
label(dat_table$cpk) = "Creatinine phosphokinase (U/L)"
dat_table$event <- factor(dat$event, levels = c(0, 1),
                          labels = c("Censored", "Event"))

pvalue <- function(x, ...) {
  # Remove the "overall" column
    x <- x[names(x) != "overall"]
    # Construct vectors of data y, and groups (strata) g
    y <- unlist(x)
    g <- factor(rep(1:length(x), times = sapply(x, length)))
    if (is.numeric(y)) {
        # For numeric variables, perform a standard 2-sample t-test
        p <- t.test(y ~ g)$p.value
    } else {
        # For categorical variables, perform a chi-squared test of independence
        p <- chisq.test(table(y, g))$p.value
    }
    # Format the p-value, using an HTML entity for the less-than sign.
    # The initial empty string places the output on the line below the variable label.
    c("", sub("<", "<", format.pval(p, digits = 3, eps = 0.001)))
}
caption = "Table 1: Descriptive Statistics Table"

table1 = table1(~ time + age + gender + smoking + diabetes + bp + EF_cat + 
                  anemia + sodium + creatinine + cpk + platelets | event,
                  data = dat_table,
                extra.col = list(`P-value` = pvalue), caption = caption)
t1kable(table1) |> kable_styling(font_size = 8, latex_options = "HOLD_position")
```

Based on the descriptive table, we observe that the mean survival time for deletions and events is 158 days and 70.9 days, respectively. Since we have the complete dataset, there is no need to worry about missing values issue. The table also lists the p-values for each variable with some having relatively large p-values. However, we still need to check the distribution of each variable ^[Histograms for continuous variables and bar charts for categorical variables] and determine which variables need to be transformed.

```{r fig.align='center', fig.height=5, fig.width=8}
# Data contains the continuous vars only
cont_dat = dat |> 
  dplyr::select(age, sodium, creatinine, platelets, cpk)
# Long format 
cont_dat.long = cont_dat |> 
  pivot_longer(cols = c(age, sodium, creatinine, platelets, cpk))
# Plot the continuous variable histograms
cont_hist = ggplot(data = cont_dat.long, aes(x = value)) +
  geom_histogram(aes(fill = name), bins = 30) +
  facet_wrap(~name, scales = "free") +
  labs(x = "Value", y = "Count",
       title = "Figure 1.1: Histograms of Continuous Variables") +
  theme_bw() +
  theme(legend.position = "none")
cont_hist

# Data contains the categorical vars only
cate_data = dat |> 
  dplyr::select(event, gender, smoking, diabetes, bp, anemia, EF_cat)
# Long format 
cate_dat.long = cate_data |> 
  pivot_longer(cols = c(event, gender, smoking, diabetes, bp, anemia, EF_cat))
# Plot the categorical variable barplots
cate_barplot = ggplot(cate_dat.long, aes(x = value, fill = value)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.3) +
  facet_wrap(~name, scales = "free") +
  labs(x = "Category", y = "Count", fill = "Category",
       title = "Figure 1.2: Bar Charts of Categorical Variables") +
  theme_bw() +
  theme(legend.position = "none") +
  ylim(0, 240)
cate_barplot
```

After checking the histograms, two continuous variables creatinine phosphokinase (cpk) and serum creatinine are right-skewed. We decide to log-transformed both of them for further model fitting. The new log-transformed variables follow a little more symmetric-like distribution and are stored as `logcre` and `logcpk`.

```{r}
dat_log = dat |> 
  mutate(cpk_log = log(cpk + 1),
         creatinine_log = log(creatinine + 1))
```

# Methods
## Nonparametric Methods

In our analysis, we applied life table, Kaplan-Meier and Fleming-Harrington Curves to estimate the survival function. All three approaches can handle censored data. 

The life table is particularly useful for larger sample sizes and when the data are grouped into intervals. The survival probability at each interval is estimated as:
  
$$
\hat{S}_L(t_i)=\prod_{t_{i-1}<t}(1-\frac{d_{i}}{{n_{i}'}})
$$

where $d_i$ is the number of events in interval^[This is the survival function at the end of interval. However, R often reports the survival function at the beginning of the interval] $[t_{i-1}, t_i]$, $n_i'$ is the average number at risk in the interval $[t_{i-1}, t_i]$.
    
The Kaplan-Meier curve allows for varying follow-up times and censored data, making it versatile for smaller samples and individual subject data. It provides a visual representation of the survival experience of the cohort over time. The Kaplan-Meier estimate of survival function can be mathematically expressed as: 
      
$$ 
\hat S_K(t)=\prod_{t_i \le t} [1-\frac{d_i}{n_i}]
$$
where $d_i$ is the number of events at time $t_i$ and $n_i$ is the number at risk at $t_i^-$, and $c_i$ is the number of censored during the interval $[t_i, t_{i+1}]$  
      
Unlike the Kaplan-Meier estimator, the Fleming-Harrington estimator^[Also known as Nelson-Aalen estimator] is designed to weight events differently over time in survival analysis. It focuses on estimating the cumulative hazard function. The estimated survival probability can be computed as:
      
$$ 
\hat S_F(t)= \prod_{t_i \le t} \exp[-\frac{d_i}{n_i}]
$$
where the $d_i$, $n_i$ and $c_i$ conditions are the same as K-M estimator above, It is true that $\hat S_F(t) \geq \hat S_K(t)$ because $\exp{[-\frac{d_i}{n_i}]}$ is always great and equal to $1 - \frac{d_i}{n_i}$. 
    
Both K-M and F-H survival curves are presented in the **Result** section for further comparison.
    
## Hypothesis Testing
    
The Log-Rank test focuses on comparing the number of observed to expected events across the groups at each time point. The test statistic^[This is the log-rank test statistics with tie] is calculated as:
      
$$
\frac{L}{\sqrt{\text{Var}(L)}} = \frac{\sum_{i=1}^{k}(d_{0i} - e_{0i})}{\sum_{i=1}^{k}\sqrt{\frac{n_{0i}n_{1i}d_i(n_i-d_i)}{n_i^2(n_i-1)}}} \sim N(0, 1)
$$
      
The Gehan's Wilcoxon test^[Also known as the Breslow test] gives more weight to events at earlier time points. It achieves a greater sensitivity to differences in survival that manifest at the beginning of the observation period. The test statistic is calculated as:

$$
\frac{L}{\sqrt{\text{Var}(L)}} = \frac{\sum_{i=1}^{k}n_i(d_{0i} - e_{0i})}{\sum_{i=1}^{k}\sqrt{\frac{n_{0i}n_{1i}d_i(n_i-d_i)}{n_i-1}}} \sim N(0,1)
$$

The Gehan's Wilcoxon test is actually a special case of weighted log-rank test for weight equals $n_i$.
    
    
## Proportional Hazard Models
    
We use three propositional hazard models to evaluate the effect of several factors on survival time. It allows us to examine how specified factors influence the rate of the event that we are interested in at a particular point in time. The rate here is the hazard rate. Proportional hazard model is the primary regression model to investigate the effectiveness of treatment $X$ over survival time $T$, where the $i_{th}$ patient at a time $t$ \
is\
$$h_i(t) = h_0(t)\exp[{\beta_1X_{i1}+\beta_2X_{i2}+\ldots+\beta_p X_{ip}}]$$
where

\begin{itemize}
    
\item $h_0(t)$ is the baseline hazard function
    
\item $h_i(t)$ is the hazard function determined by a set of $p$ covariates $(X_{i1},\ X_{i2},\ ...,\ X_{ip})$
      
\item $(\beta_1,\ \beta_2,\ ...,\ \beta_p)$ are the coefficients which measure the impact of covariates.
    
\end{itemize}
    
The **proportional hazard** can be expressed as ratio of two hazard functions at time t in two individuals or groups with covariates $X$ and $X'$, and does not depend on $t$. 

$$\frac{h(t|X = x)}{h(t|X = x')} = e^{\beta({x-x'})}$$

There are different ways to formulate the baseline hazard function $h_0(t)$, which lead to different models and estimations. 

### Cox Proportational Hazard Model

The Cox proportional hazard model is a semi-parametric model which does not assume a particular baseline hazard function $\tilde{h}_0(t)$. In contrast to parametric PH models which use the full likelihood, the Cox PH model is formulated by partial likelihood because there is very limited information on $\beta$ beyond $L_p(\beta)$. The model is given by:

$$
h_i(t) = \tilde{h}_0(t) \exp[\beta_1 X_{i1} + \beta_2 X_{i2} + \ldots + \beta_p X_{ip}] \\
$$

### Weibull Proportional Hazard Model

The Weibull model is a popular parametric proportional hazard model which assumes a specific functional form for the hazard rate, which can either increase or decrease over time. Its parameters are intuitively interpretable, with the shape parameter distinctly indicating whether the hazard rate is increasing, decreasing, or constant.

$$
\begin{aligned}
h_i(t) &= \lambda \gamma t^{\gamma - 1} \exp(\beta_1 X_{i1} + \beta_2 X_{i2} + \ldots + \beta_p X_{ip}) \\
\end{aligned}
$$

where $\lambda$ is the scale parameter, and $\gamma$ is the shape parameter.

## Model Selection
### Survival Tree

The survival tree method is a non-parametric approach used in survival analysis for model selection and identifying significant predictors of time-to-event outcomes. It involves segmenting the data into homogeneous subgroups based on the values of explanatory variables. The method constructs a tree structure where each node represents a subset of the dataset, and each split is based on the value of a predictor variable that best separates the data in terms of survival. Mathematically, this process involves recursively partitioning the data to maximize a criterion like the log-rank statistic. At each node, the split is chosen to maximize the difference in survival between the resulting subgroups. This can be represented as:

$$\text{Max}_{v,s}[\chi^2_{LR}(v, s)]$$
where $\chi^2_{LR}(v, s)$ is the log-rank test statistic computed for a split $s$ on variable $v$. The process continues until a stopping criterion is met, typically based on the minimum number of observations in a node or a minimum improvement in the survival difference. The result is a tree where the paths from the root to the leaves represent rules for predicting survival, offering a visual and interpretable model of the factors affecting the time to an event like death in this study.

### Stepwise Selection
In model selection process, we incorporated bidirectional stepwise selection, alongside using various model assessment criteria such as Akaike Information Criterion (AIC), Corrected Akaike Information Criterion (AICc), and Schwarz Bayesian Criterion (SBC). This comprehensive approach enhanced our ability to identify the most appropriate model for our data. 

We chose the final model based on AIC in our survival analysis due to its effective balance between model complexity and fit, particularly valuable in preventing overfitting in complex models. Additionally, given our sufficiently large sample size, AIC provided a more appropriate measure compared to AICc, and its less stringent penalty compared to SBC was better suited for our data's scale and complexity. The AIC for the survival model is as follows (Collett et al., 1999):

The formula for the Cox model being:

$$
AIC_{cox} = -2\partial \mathcal{L}(\theta;x) +2k
$$

In this equation, $k$ represents the number of parameters in the model. The term $2k$ serves as a penalty to discourage overfitting by complex models and $\mathcal{L}(\theta;x)$ indicates log-likelihood of parameter $\theta$ in the sample $x$.

For other survival models, the AIC adapts as follows with different penalty term: 

$$
AIC = -2\mathcal{L}(\theta;x) + 2(p+2+k)
$$

where $k = 0$ for the exponential model, $k = 1$ for the Weibull, log-logistic and log-normal models, and $k = 2$ for the generalized gamma model.

## Model Checking
### Graphical Approach

**Cox Proportional Hazard Model:**

The Cox proportional hazard model has two main assumptions. One is that the that the hazard functions of the survival curves of the different strata are proportional at time t. The other assumption is that the relationship between the $\log h(t)$, and each covariate is linear. We can compare the survival curves visually to check the PH assumption. One of the most commonly used plot is $\log(-\log\hat{S}(t|Z = z))$ over $\log t$. Since we know:

$$\log(-\log\hat{S}(t|Z = z))-\log(-\log\hat{S}_0(t)) = \beta$$
where $Z$ is a binary group indicator and the survival probability is usually estimated by K-M estimator. The parallel curves in the plot indicates the hazard ratio across the variable of interest is proportional at time t.

Another graphical method is to compare the differences between the fitted survival functions and observed K-M estimates from our PH model. If the fitted survival curse is closed to the observed K-M estimated survival curve, our PH assumption holds. 

**Parametric Proportional Hazard Model:**

In the parametric proportional hazard models, we can use both $-\log \hat{S}(t)$ plot and $\log(-\log\hat{S}(t))$ to confirm if the hazard rate is constant. In other words, it can help us choose a proper distribution before fitting the models. For $-\log \hat{S}(t)$ plot, a straight line means constant hazard rate and the distribution should be exponential. Otherwise, Weibull model is better. In $\log(-\log\hat{S}(t))$ plot, if the slope of the straight line equals 1, then hazard rate should be constant. And if it is not, we choose Weibull model.

## Residuals and Interaction Test
Schoenfeld residuals are used to test the assumption of proportional hazards. If the proportional hazards assumption holds, these residuals should not show any systematic trend when plotted against time. In other words, if some covariate was dropped from a previous model selection and shows a regression line of zero in that figure, then we need to consider whether to add that variable of interest to our Cox proportional hazards model.

## Model Validation

### ROC Curves and AUC

In our analysis, we employed time-dependent Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) values to evaluate the discriminative ability of our Cox proportional hazards model over time. Specifically, we focused on two clinically relevant time points: 50 days and 250 days (Ahmad et al., 2017). The ROC curve is a graphical representation that illustrates the diagnostic ability of a binary classifier system by plotting the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings. AUC, a key summary measure of the ROC curve, quantifies the overall ability of the model to discriminate between individuals who will experience the event and those who will not, irrespective of the chosen probability threshold (Heagerty & Zheng, 2005). Generally, higher AUC values indicate better discriminative ability.

### C-Index

The concordance index (C-index) was calculated to assess the predictive accuracy of our model. This metric is a measure of the model's ability to correctly rank the survival times of pairs of individuals, considering censored data (Steyerberg & Vergouwe, 2014). The C-index is calculated through pairwise comparisons, where a pair is concordant if the individual predicted to have a shorter survival time indeed experiences the event earlier than the other individual in the pair (Steyerberg & Vergouwe, 2014). A C-index of 0.5 suggests no better predictive accuracy than random chance, while a value of 1 indicates perfect prediction.

### Calibration Slope

To evaluate the calibration of our model, we focused on the calibration slope. Calibration reflects the agreement between observed outcomes and predicted probabilities and the calibration slope assesses whether the predicted risks are of the correct magnitude (Steyerberg & Vergouwe, 2014). A slope of 1 indicates perfect calibration, meaning the model's predicted probabilities are accurately scaled. We calculated the calibration slope using logistic regression within a bootstrap framework, which allowed us to robustly assess the scale of the predicted risks relative to the actual event occurrences. The bootstrap approach, involving resampling the dataset 400 times, provided a more comprehensive understanding of the model's calibration under varying sample conditions.

# Results

## Nonparametric Methods
### Life Table

```{r}
nonpara_dat = dat_log |> 
  dplyr::select(-c(EF, cpk, creatinine)) |> 
  relocate(time, event, EF_cat, smoking, everything()) |> 
  mutate(event = as.numeric(event) - 1)
nonpara_male = nonpara_dat |> filter(gender == 1)
nonpara_female = nonpara_dat |> filter(gender == 0)
```

```{r}
life_table_male <- lifetab2(Surv(time, event) ~ 1, data = nonpara_male,
                            breaks = seq(0, 300, 30))
life_table_female <- lifetab2(Surv(time, event) ~ 1, data = nonpara_female,
                              breaks = seq(0, 300, 30))
life_table_male |> kable(booktabs = T,
                          caption = "Table 2.1: Heart Failure Life Table (Male)") |> 
  kable_styling(latex_options = c("HOLD_position"), font_size = 6) 
life_table_female |> kable(booktabs = T,
                            caption = "Table 2.2: Heart Failure Life Table (Female)") |> 
  kable_styling(latex_options = c("HOLD_position"), font_size = 6)
```

**Table 2.1** and **Table 2.2** represent the lifetable with a time break of 30 days (one month), stratified by gender. According to the table, we find that the last line (270-300 days) shows a survival probability larger than 0.5 for both genders (0.54 for male and 0.59 for female). The median survival time is longer than 300 days (10 months), indicating a high life expectancy and improved health care. Moreover, males have a relatively shorter survival time than females based on the life table. This hypothesis needs future testing in the following modeling fit.

### The Kaplan-Meier and Fleming-Harrington Model

```{r fig.width=12, fig.height=5}
km = survfit(Surv(time, event) ~ gender, data = nonpara_dat)
fh <- survfit(Surv(time, event) ~ gender, data = nonpara_dat, type = "fh")
km_plot = 
  km |> autoplot() +
  labs(y = "S(t)",
       x = "Time",
       subtitle = "Figure 2.1. Kaplan-Meier Survival Curve By Gender",
       color = "Gender", fill = 'Gender') + theme(legend.position = "none")
fh_plot = 
  fh |> autoplot() +
  labs(y = "S(t)",
       x = "Time",
       subtitle = "Figure 2.2. Fleming-Harrington Survival Curve By Gender",
       color = "Gender", fill = 'Gender')
km_plot + fh_plot
```

The Kaplan-Meier and Fleming-Harrington have similar trends and show no significant difference between genders. Given that the p-value is relatively high (p-value = 0.95) for both Kaplan-Meier and Fleming-Harrington estimators, we can further make sure that no significant difference appears in the survival experience between males and females.

## Hypothesis Testing

### Log-Rank test and Gehan's Wilcoxon test

```{r logrank}
logrank_test <- survdiff(Surv(time, event) ~ gender, data = nonpara_dat)
wilcox_result <- wilcox.test(time ~ gender, data = nonpara_dat)
results1 <- tibble(
  Gender = c(0, 1),
  N = c(105, 194),
  Observed = c(34,62),
  Expected = c(34.3, 61.7),
  '11' = c(0.00254, 0.00141),
  '22' = c(0.00397, 0.00397)
)

results2 <- tibble(
  Test = c("Log Rank Test", "Wilcoxon Test"),
  "Chi square" = c(0, 0),
  df = c(1, 1),
  "p-value" = c(0.950, 0.765)
)

results_table1 <- kable(results1, align = "c", booktabs = T, escape = F,
caption = "Figure 3.1: Comparison of Survival Experience Between Males and Females by Log-Rank Test",
col.names = c("Gender", "N", "Observed", "Expected", "$\\frac{(O-E)^2}{E}$", "$\\frac{(O-E)^2}{V}$")) |>
  kable_styling(latex_options = c("HOLD_position"))

results_table2 <- kable(results2, align = "c", booktabs = T, 
caption = "Figure 3.2: P-values for the Log-rank and Gehan's Wilcoxon test") |>
  kable_styling(latex_options = c("HOLD_position"))

results_table1
results_table2
```

The Log-Rank test and the Gehan's Wilcoxon test can be used to test for differences in survival experience between genders. Reviewing the results from the table, we find that both the Log-Rank test and the Gehan's Wilcoxon test have provided a similar result and gave a p-value greater than 0.05. This indicates that we failed to reject the null hypothesis at the significance level of 0.05, and we can state there is no statistically significant difference in survival experiences between males and females.

## Model Selection
### Survival Tree

```{r fig.align='center', fig.width=10, fig.height=6}
surv_obj <- Surv(time = nonpara_dat$time, event = nonpara_dat$event)
surv_tree <- rpart(surv_obj ~ gender + smoking + diabetes + bp + anemia + age + EF_cat + sodium + creatinine_log + platelets + cpk_log,
                   data = nonpara_dat, method = "exp")
rpart.plot::rpart.plot(surv_tree, main = "Figure 3: Results of Survival Tree")
```

The survival tree depicted in the image stratifies patients based on factors affecting survival. At the first level, patients are divided by `EF_cat`, suggesting that EF is a significant factor in survival. For patients with medium to high EF, age is the next discriminator, indicating its importance in survival for this subgroup. Among those with lower EF, log-transformed creatinine levels further split the cohort, underscoring renal function's role in survival. The tree branches into additional factors such as log-transformed cpk levels, the presence of diabetes, and sodium levels, highlighting their contribution to survival outcomes. Terminal nodes provide risk ratios and the proportion of patients experiencing the event, illustrating the combined effect of these variables on patient survival. This tree model, therefore, offers a nuanced view of patient risk profiles, emphasizing the multifactorial nature of survival in this patient population.

### Stepwise Selection

$$
h(t) = h_0(t)\exp[\beta_1{Age} + \beta_2{EF_{Medium}} + \beta_3{EF_{High}} + \beta_4{BP}+\beta_5{Sodium} + \beta_6\log({Creatinine}+1)]
$$


```{r}
# raw data
raw_data <- data |>
  arrange(TIME) |>
  janitor::clean_names() |>
  mutate(platelets = pletelets,
         anemia = anaemia)

# model data
model_data <- dat |>
  mutate(event = as.numeric(event))

## create dummy variable for categorical variable
heart_data <- model.matrix(EF~ EF_cat, data = model_data)[,-1] |>
  as.data.frame()

## create data frame for stepwiseCox
heart_data <- cbind(raw_data, heart_data) 
stepwise_data <- heart_data |>
  mutate(logcre=log(creatinine+1),
         logcpk = log(cpk+1)) |>
  dplyr::select(-creatinine, -cpk, -ejection_fraction)
```

```{r}
# Variable selection using stepwise Cox model using Sl
stepwise_model1 <- stepwiseCox(Surv(time, event) ~ gender + smoking + diabetes + bp + 
                                 anemia + age + sodium + platelets + logcre + logcpk + 
                                 EF_catMedium + EF_catHigh,
                               data = stepwise_data,
                               select = "SL",
                               # significant level for entry
                               sle = 0.25,
                               # significant level for stay
                               sls = 0.15,
                               method = "efron",
                               weights = NULL,
                               best = NULL)
# 7 variables are selected: logcre, age, EF_catMedium, EF_catHigh, bp, sodium, anemia  

## Variable selection using stepwise Cox model using AIC
stepwise_model2 <- stepwiseCox(Surv(time, event) ~ gender + smoking + diabetes + bp + 
                                 anemia + age + sodium + platelets + logcre + logcpk + 
                                 EF_catMedium + EF_catHigh,
                               data = stepwise_data,
                               selection = "bidirection",
                               select = "AIC",
                               # significant level for entry
                               sle = 0.25,
                               # significant level for stay
                               sls = 0.15,
                               method = "efron",
                               weights = NULL,
                               best = NULL)
# 6 variables are selected: logcre, age, EF_catMedium, EF_catHigh, bp, sodium

### Variable selection using stepwise Cox model using AICc
stepwise_model3 <- stepwiseCox(Surv(time, event) ~ gender + smoking + diabetes + bp + 
                                 anemia + age + sodium + platelets + logcre + logcpk + 
                                 EF_catMedium + EF_catHigh,
                               data = stepwise_data,
                               selection = "bidirection",
                               select = "AICc",
                               # significant level for entry
                               sle = 0.25,
                               # significant level for stay
                               sls = 0.15,
                               method = "efron",
                               weights = NULL,
                               best = NULL)
# AICc 9 variables: logcre, age, EF_catMedium, EF_catHigh, bp, sodium, anemia, logcpk, diabetes 

### Variable selection using stepwise Cox model using SBC
stepwise_model4 <- stepwiseCox(Surv(time, event) ~ gender + smoking + diabetes + bp + 
                                 anemia + age + sodium + platelets + logcre + logcpk + 
                                 EF_catMedium + EF_catHigh,
                               data = stepwise_data,
                               selection = "bidirection",
                               select = "SBC",
                               # significant level for entry
                               sle = 0.25,
                               # significant level for stay
                               sls = 0.15,
                               method = "efron",
                               weights = NULL,
                               best = NULL)
# SBC 5 variables: logcre, age, EF_catMedium, EF_catHigh, bp
```

```{r selection}
# Extract data from the models
steps2 <- stepwise_model3$`Process of Selection`[, "Step"]
enteredEffect1 <- stepwise_model3$`Process of Selection`[, "EnteredEffect"]
sl1 <- stepwise_model1$`Process of Selection`[, "SL"]
aic2 <- stepwise_model2$`Process of Selection`[, "AIC"]
aic3 <- stepwise_model3$`Process of Selection`[, "AICc"]
sbc4 <- stepwise_model4$`Process of Selection`[, "SBC"]

# Determine the maximum length
max_len <- max(sapply(list(steps2, enteredEffect1, sl1, aic2, aic3, sbc4), length))

# Function to pad vectors with NA to make their length equal to max_len
pad_vector <- function(vec, max_len) {
  length(vec) <- max_len
  return(vec)
}

# Apply the function to each vector
steps2 <- pad_vector(steps2, max_len)
enteredEffect1 <- pad_vector(enteredEffect1, max_len)
sl1 <- pad_vector(sl1, max_len)
aic2 <- pad_vector(aic2, max_len)
aic3 <- pad_vector(aic3, max_len)
sbc4 <- pad_vector(sbc4, max_len)

# Create the data frame
model_selection <- data.frame(
  Step = steps2,
  EnteredEffect = enteredEffect1,
  SL = round(as.numeric(sl1),4),
  AIC = round(as.numeric(aic2), 2),
  AICc = round(as.numeric(aic3), 2),
  SBC = round(as.numeric(sbc4), 2)
)
model_selection[is.na(model_selection)] <- c("-")

# Create table using kable
model_selection |> kable(booktabs = T,
                         caption = "Table 3: Summary of Model Selection", digits = 4) |>
  kable_styling(latex_options = c("HOLD_position"), font_size = 10) 
```

The **Table 3** summarizes the Cox model selection process, indicating `logcre`, `age`, `EF` categories, and `BP` as persistent predictors across the top four models. The AIC favors `logcre` and `age` for their significant contributions to model fit relative to added complexity, emphasizing model fit over parameter count. 

However, with large sample size, the AICc modification slightly adjusts these values, shifting the preference toward other variables like `diabetes`, which shows the lowest AICc, suggesting a strong impact on the model when accounting for sample size. The SBC, with its more substantial penalty for complexity, particularly at larger sample sizes, selects `BP` as the best variable, underscoring its contribution to the model's explanatory power without excessive complexity. 

We choose AIC for model selection, given its consistency with SL findings, which jointly highlight `logcre` and `age` as key predictors. This consistent identification underscores their substantial impact on model accuracy while maintaining simplicity, justifying their selection.
 
## Semi-parametric Models

The final model obtained from Stepwise Selection using AIC contains creatinine, age, ejection fraction, blood pressure status, sodium covariates.

### Model Checking

Before fitting the Cox proportional hazard model, we need to check whether our variables hold the PH assumption^[See the Method Section for details]. The $\log(-\log\hat{S}(t|Z = z))$ over $\log t$ plot and observed survival versus estimated survival curves are provided below. We have multiple variables remained after model selection, so we randomly took two of them (`age` and `logcre`) for the PH assumption check. Since both `age` and `logcre`^[Since 1.5 mg/dL is the clinical threshold of creatinine, so we categorized log(creatinine + 1) > log(2.5) as "High", otherwise, it's in "Low" group. And people in "High" group should be regarded as renal dysfunction.] are continuous variable, we categorized it into two groups and recoded as "Low" and "High", respectively. 

```{r fig.align='center', fig.width=10, fig.height=6}
mc_dat = nonpara_dat %>% mutate(age_cat = case_when(age <= mean(age) ~ "Low", age > mean(age) ~ "High")) %>% 
  mutate(cre_cat = case_when(creatinine_log <= log(2.5) ~ "Low", 
                             creatinine_log > log(2.5) ~ "High")) %>% 
  mutate(age_cat = factor(age_cat)) %>% 
  mutate(cre_cat = factor(cre_cat)) %>% 
  as.data.frame()
mc_surv_age = survfit(Surv(time, event == 1) ~ age_cat, data = mc_dat)
mc_surv_cre = survfit(Surv(time, event == 1) ~ cre_cat, data = mc_dat)
mc_age_surv_log = survfit(Surv(log(time + 1), event == 1) ~ age_cat, data = mc_dat)
mc_cre_surv_log = survfit(Surv(log(time + 1), event == 1) ~ cre_cat, data = mc_dat)

g1 = ggsurvplot(mc_age_surv_log, data = mc_dat, fun = "cloglog", risk.table = FALSE, 
                xlab = "log(time)", ylab = "log[-log(Survival Probability)]",
                ggtheme = theme_minimal(), xlim = c(1.5, 6)) +
  labs(title = "Figure 4.1: Log of Negative Log of Estimated Survival Functions \nby Age Group")
g2 = ggsurvplot(mc_cre_surv_log, data = mc_dat, fun = "cloglog", risk.table = FALSE, 
                xlab = "log(time)", ylab = "log[-log(Survival Probability)]",
                ggtheme = theme_minimal(), xlim = c(1.5,6)) +
  labs(title = "Figure 4.2: Log of Negative Log of Estimated Survival Functions \nby Log-transformed Creatinine Group")
gridExtra::grid.arrange(g1$plot, g2$plot, nrow = 2)

g3.1 = ggsurvplot(mc_surv_age, data = mc_dat, risk.table = FALSE, ggtheme = theme_minimal())
g3.2 = ggadjustedcurves(coxph(Surv(time, event == 1) ~ age_cat, data = mc_dat), variable = "age_cat", 
                        data = mc_dat, ggtheme = theme_minimal())
km_fit = g3.1$plot$data
cox_fit = g3.2$data
cox_fit$age_cat = cox_fit$variable

g3 = ggplot(cox_fit, aes(x = time, y = surv, group = age_cat, color = age_cat)) + geom_step() +
  geom_step(data = km_fit, aes(x = time, y = surv, group = age_cat, color = age_cat), lty = 3) + 
  labs(title = "Figure 5.1: Plot of Observed vs. Fitted Survival By Age Group", y = "Survival Distribution Function Estimate", 
  caption = "Straight line: Fitted Survival \nDashed line: Observed Survival") +
  theme_minimal() +
  theme(legend.position = "top") +
  scale_color_manual(
    name = "Age Group",
    values = c("blue", "red"),
    labels = c("Low", "High") 
  )

  
g4.1 = ggsurvplot(mc_surv_cre, data = mc_dat, risk.table = FALSE, ggtheme = theme_minimal())
g4.2 = ggadjustedcurves(coxph(Surv(time, event == 1) ~ cre_cat, data = mc_dat), variable = "cre_cat", 
                        data = mc_dat, ggtheme = theme_minimal())
km_fit = g4.1$plot$data
cox_fit = g4.2$data
cox_fit$cre_cat = cox_fit$variable

g4 = ggplot(cox_fit, aes(x = time, y = surv, group = cre_cat, color = cre_cat)) + geom_step() +
  geom_step(data = km_fit, aes(x = time, y = surv, group = cre_cat, color = cre_cat), lty = 3) + 
  labs(title = "Figure 5.2: Plot of Observed vs. Fitted Survival By Creatinine Group", y = "Survival Distribution Function Estimate", 
  caption = "Straight line: Fitted Survival \nDashed line: Observed Survival") +
  theme_minimal() +
  theme(legend.position = "top") +
  scale_color_manual(
    name = "Creatinine Group",
    values = c("blue", "red"), # Change these colors based on your data
    labels = c("Low", "High") # Custom labels for the legend
  )

g3 / g4
```

```{r fig.align='center', fig.width=10, fig.height = 4, fig.cap="Figure 6.1: Schoenfeld Test For Log-transformed Creatinine"}
scho <- coxph(Surv(time, event == 1) ~ EF_cat + bp + creatinine_log + age + sodium, data = mc_dat)
ggcoxzph(cox.zph(scho), var = c("creatinine_log"), df = 2, nsmo = 1000)
```

```{r fig.align='center', fig.width=10, fig.height = 4, fig.cap="Figure 6.2: Schoenfeld Test For Age"}
ggcoxzph(cox.zph(scho), var = c("age"), df = 2, nsmo = 1000)
```

\newpage

Obviously, the curves in **Figure 4.1** and **Figure 4.2** are parallel with each other, indicating the proportional hazard assumption hold. For the observed survival versus estimated survival plot (**Figure 5.1** and **Figure 5.2**), the straight curve and dashed curve are close to each other, which means the proportional hazard ratio is proportional for both age and creatinine groups. These findings are also consistent with what we observed in the Schoenfeld residual plots (**Figure 6.1** and **Figure 6.2**) of the fitted model. We chose to input `age` and `logcre` variables and found a regression lines with a slope close to zero for both.

### Cox Model Fitting and Results

```{r final model results}
# Create table using kable
model_summary <- tibble(stepwise_model2$`Coefficients of the Selected Variables`) %>% select(-Variable)

model_summary <- model_summary |>
  mutate(var = c("logcre", "age", "EF\\_catMedium", "EF\\_catHigh", "bp", "sodium"),
         coef = as.numeric(coef),
        `exp(coef)` = as.numeric(`exp(coef)`),
        `se(coef)` = as.numeric(`se(coef)`),
        z = as.numeric(z),
        `Pr(>|z|)` = as.numeric(`Pr(>|z|)`)) %>% 
  relocate(var, coef, `exp(coef)`, `se(coef)`, z, `Pr(>|z|)`)

model_summary |> kable(booktabs = T, escape = F,
      caption = "Table 4: Summary of Cox Proportional Hazard Model", 
      digits = 4, row.names = TRUE, 
      col.names = c("Variable", "$\\beta$", "$E(\\beta)$", "$Var(\\beta)$", "Z test statistics","P-value")) |>
  kable_styling(latex_options = c("HOLD_position"), font_size = 10) 
```

## Parametric Models
### Parametric Model Checking

```{r fig.width=10}
mc_surv_age = survfit(Surv(time, event == 1) ~ age_cat, data = mc_dat)
mc_surv_cre = survfit(Surv(time, event == 1) ~ cre_cat, data = mc_dat)

plot(mc_surv_age, col = c("red", "blue"), 
     fun = "cumhaz", xlab = "Time(Days)", ylab = "-logS(t)", 
     main = "Figure 7.1: Negative Log of Estimated Survival Functions For Age Groups")
legend("topleft", legend = c("High", "Low"), 
       title = "Age Group", col = c("red", "blue"), lty = 1)

plot(mc_surv_cre, col = c("red", "blue"), 
     fun = "cumhaz", xlab = "Time(Days)", ylab = "-logS(t)", 
     main = "Figure 7.2: Negative Log of Estimated Survival Functions For Creatinine Groups")
legend("topleft", legend = c("High", "Low"), 
       title = "Creatinine Group", col = c("red", "blue"), lty = 1)
```

Since we have already created the $\log(-\log\hat{S}(t)$ (**Figure 4.1** and **Figure 4.2**) for `age` and `logcre`, and the slopes do not strictly equal to 1. Now we also check the $-\log\hat{S}(t)$ plot (**Figure 7.1** and **Figure 7.2**) for same variables. The curves for both two plots seems not to be straight and nonlinear. We suggest Weibull distributions for parametric proportional hazard models. 


### Parametric Models Fitting and Result

```{r weibull}
fit_weibull = eha::phreg(Surv(time, event) ~ gender + smoking + diabetes + bp + anemia + 
                  age + EF_cat+ sodium + platelets + log(creatinine+1) + log(cpk+1), 
                data = model_data, dist = "weibull")
# summary(fit_weibull)

# AIC Both direction
library(MASS)
# stepAIC(fit_weibull)

final_weibull <- eha::phreg(formula = Surv(time, event) ~ bp + age + EF_catMedium + 
                          EF_catHigh + sodium + logcre, data = stepwise_data, dist = "weibull")

# Extract relevant information
weibull_summary <- tibble(
  Variable = c("bp", "age", "EF\\_catMedium", "EF\\_catHigh", "sodium", "logcre", "log(scale)", "log(shape)"),
  Coef = round(as.vector(final_weibull$coefficients),4),
  `Exp(Coef)` = round(exp(as.vector(final_weibull$coefficients)),4),
  `se(Coef)` = round(sqrt(as.vector(diag(final_weibull[["var"]]))),4),
  `Wald p` = round(1 - pchisq((as.vector(final_weibull$coefficients)/sqrt(as.vector(diag(final_weibull[["var"]]))))^2,1),4))

# Create table using kable
weibull_summary |> kable(booktabs = T, escape = F, caption = "Table 5: Summary of Weibull PH Model Fitting", 
                         digits = 4, col.names = c("Variable", "$\\beta$", "$E(\\beta)$", "$Var(\\beta)$", "Wald P-value")) |>
  kable_styling(latex_options = c("HOLD_position"), font_size = 10) 
```

## Model Validation 

### ROC Curves and AUC


```{r, fig.align='center', fig.height=5, fig.width=8}
step_model_final <- coxph(Surv(time, event == 1) ~ EF_catHigh +EF_catMedium + bp + logcre + age + sodium, data = stepwise_data)

# Calculate predicted risks
predicted_risks <- predict(step_model_final, newdata = stepwise_data, type = "risk")
 # Time points for ROC analysis
time_points <- c(50, 250)
 
# Calculate ROC curves at specified times
roc_50 <- timeROC(T = stepwise_data$time, delta = stepwise_data$event, marker = predicted_risks, times = 50, cause = 1)
roc_250 <- timeROC(T = stepwise_data$time, delta = stepwise_data$event, marker = predicted_risks, times = 250, cause = 1)
 
# Extract AUC values
auc_50 <- roc_50$AUC
auc_250 <- roc_250$AUC
 
# Print AUC values
#print(paste("AUC at 50 days:", auc_50))
#print(paste("AUC at 250 days:", auc_250))

# Plot ROC curves
plot(roc_50$FP, roc_50$TP, type = "l", col = "red", xlab = "1 - Specificity", ylab = "Sensitivity", main = "Figure 8: Time-Dependent ROC Curves for 50 and 250 Days")
lines(roc_250$FP, roc_250$TP, type = "l", col = "blue")
legend("bottomright", legend = c("50 days", "250 days"), col = c("red", "blue"), lty = 1)
abline(0, 1, col = "black", lty = 2)
```


Using the Cox proportional model with the 5 selected predictors, our time-dependent ROC analysis at 50 days yielded an AUC of approximately 0.736, while at 250 days, the AUC was 0.934. These values indicate that the model's ability to discriminate between those who will experience the event and those who will not improves over time. The ROC curves further visually demonstrate this improvement, with the curve for 250 days being closer to the top left corner, indicating better performance.

### C-Index

```{r}
# Define the function for calculating C-statistic
boot_c_statistic <- function(original_data, indices) {
 # Creating a bootstrap sample
  boot_data <- original_data[indices, ]
 
 # Fit the Cox model to the bootstrap sample
 fit <- coxph(Surv(time, event == 1) ~ EF_catHigh + EF_catMedium + bp + logcre + age + sodium, data = stepwise_data)
   
   # Calculate the concordance statistic using the updated function
   concordance <- concordance(fit)$concordance
   return(concordance)
 }
 
 # Perform bootstrapping for C-statistic
 set.seed(123) # for reproducibility
 boot_results_c_stat <- boot(data = stepwise_data, statistic = boot_c_statistic, R = 400)
 
 # Calculate the average C-statistic
 mean_c_stat <- mean(boot_results_c_stat$t)
 #print(mean_c_stat)
```

The average C-index calculated through bootstrapping (n = 400) was 0.737 This suggests that in about 74% of pairwise comparisons, our model correctly ranks the survival times. A C-index of around 0.74 is generally indicative of good predictive ability, especially in clinical settings where accurate risk stratification is crucial for treatment planning.

### Calibration Slope

```{r, warning= FALSE}
 # Define the bootstrap function for calibration metrics using logistic regression
boot_calibration_logistic <- function(original_data, indices) {
 boot_data <- original_data[indices, ]
fit <- coxph(Surv(time, event == 1) ~ EF_catHigh + EF_catMedium + bp + logcre + age + sodium, data = stepwise_data)
   
   
  # Predicted risks for the original dataset
   predicted_risks <- predict(fit, newdata = original_data, type = "risk")
   
  # Fit a logistic model for calibration
   calibration_model_logistic <- glm(event ~ predicted_risks, data = original_data, family = "binomial")
  
   # Calibration slope (coefficient of predicted_risks)
   calibration_slope_logistic <- coef(calibration_model_logistic)["predicted_risks"]
   
   return(calibration_slope_logistic)
 }
 
 # Perform bootstrap
 set.seed(123)
 boot_results_logistic <- boot(data = stepwise_data, statistic = boot_calibration_logistic, R = 400)
 
 # Calculate the average calibration slope
mean_calibration_slope_logistic <- mean(boot_results_logistic$t)
# print(mean_calibration_slope_logistic)
```

Our calculated mean calibration slope came to approximately 1.33. This value, slightly above the ideal of 1, is significant in understanding the model's performance. The calibration slope measures the extent to which the model's predicted risks are proportionate to the observed risks. A value of 1 would indicate perfect calibration, meaning the model's predictions are perfectly aligned with the actual observed risks. Our finding of a calibration slope above 1 suggests that our model may be mildly overfitting the data, predicting slightly higher risks than what is observed.

# Discussion

According to the life table, we find that there is a slight difference in survival probability between male and female. However, the hypothesis test and model selection show that there is actually no difference. Similarities in heart failure presentation, treatment regimen, and sample size may explain the absence of sex-based differences in survival. Specifically, if the severity of heart failure was not related to gender or if patients received appropriate gender-based treatment and the sample size or characteristics of the study limited gender-specific analyses, potential differences could be masked.

Based on the findings from the Cox proportional hazards model and Weibull distribution, our analysis identified key predictors significantly associated with survival outcomes in heart failure patients. Notably, creatinine levels, as indicated by `logcre`, emerged as a critical factor. The hazard ratio (HR) of 3.0573 for `logcre` implies that an increase in creatinine levels substantially elevates the risk of adverse events, a finding echoed by existing literature highlighting the prognostic importance of serum creatinine in cardiac health. A study published in Frontiers in Cardiovascular Medicine found that postoperative serum creatinine is a significant prognostic factor for cardiac surgery patients (Zhong et al., 2021). This study showed that higher levels of postoperative serum creatinine were linked to increased hospital mortality and longer stays in the intensive care unit. Specifically, it found that patients who did not survive had significantly higher postoperative serum creatinine levels, and there was a positive correlation between these levels and lengths of ICU stay. 

Similarly, age proved to be a significant predictor, with an HR of 1.0473 suggesting that the risk increases with advancing age, underscoring age as a pivotal determinant in survival models.

Additionally, the analysis revealed the importance of ejection fraction categories. Patients with medium or high ejection fractions (`EF_catMedium` and `EF_catHigh`) demonstrated a significantly lower risk compared to those with low ejection fractions, highlighting the protective role of better cardiac function. Blood pressure (`bp`) was another significant factor; an HR of 1.7258 indicates a substantial increase in hazard with higher blood pressure levels.

In contrast, sodium levels (`sodium`) presented a nuanced picture. While higher sodium levels were associated with a slight decrease in hazard, this predictor was not statistically significant, suggesting a less definitive role in this context.

In the Weibull model analysis, the pivotal roles of `bp`, `age`, and `EF_cat` were reaffirmed. This model identified these variables as having particularly small p-values, emphasizing their statistical significance. The hazard notably increased with elevated blood pressure and advancing age. Higher ejection fractions (`EF_catMedium` and `EF_catHigh`) were significantly associated with reduced risk, which is in line with the understanding of cardiac function's protective role. While sodium levels indicated a trend towards decreased hazard, they did not emerge as a significant predictor. Importantly, this model's emphasis on creatinine levels (`logcre`) as a key factor aligns with findings from a study in Revista Espaola de Cardiologa (Zamora et al., 2007). This study highlighted that normal creatinine levels might mask underlying kidney failure, a significant prognostic factor in heart failure (Zamora et al., 2007). It identified factors such as age, gender, cause of heart failure, left ventricular ejection fraction, diabetes, and hypertension as influential, but particularly underscored creatinine clearance as an independent mortality predictor (Zamora et al., 2007). Thus, the results from the Weibull model, supported by this study, underscore the importance of considering age, ejection fraction, and creatinine levels in assessing heart failure risk, aiding in early identification and targeted interventions in clinical practice.


The nuanced findings from our model validation analysis provide a comprehensive view of our Cox model's performance. While the model exhibits strong discriminative ability, as indicated by the AUC values and C-index, our calibration assessment, particularly the calibration slope, suggests areas where improvement is needed. Notably, the calibration slope, slightly over the ideal value of one, implies a mild overestimation in risk predictions. This indicates a complex calibration scenario where the model might be overfitting to some extent.

Such overestimation, although modest, is critical in clinical settings. Accurate risk prediction is vital for informed decision-making and effective patient management. Overestimated risks might lead to more aggressive interventions than necessary, affecting patient care and resource allocation. Conversely, underestimating risks could result in missed opportunities for timely intervention. This highlights the importance of achieving a balance in predictive accuracy, ensuring that the model neither overestimates nor underestimates risks.

The observed improvement in the model's discriminative ability over time, with increasing AUC values from 50 to 250 days, underscores the dynamic nature of risk factors and their evolving impact on patient outcomes. However, the calibration results emphasize the need to focus not just on the model's ability to discriminate but also on the accuracy of its probability predictions.

Future work should, therefore, focus on refining the model's complexity and variable selection. Re-evaluating the model's components and considering alternative modeling approaches might help in aligning the predicted probabilities more closely with actual outcomes. Applying more advanced calibration techniques could also address the observed overfitting, enhancing the model's reliability. Additionally, external validation on an independent dataset is essential to confirm the model's effectiveness and applicability in different clinical contexts. Such efforts will be crucial in enhancing the model's utility and ensuring its robustness in real-world clinical applications, where precise risk assessment directly informs patient care strategies.


# Conclusions

The non-parametric method showed that more than 50% of both genders (54% for males and 59% for females) can survive for over 300 days. This may indicate a high life expectancy and improved health care. Moreover, the non-parametric method showed no significant difference in survival probability between genders. This result was later consistent with the results of the model selection. In conclusion, incorporating the insights from both semi-parametric and parametric models, particularly the Cox proportional model, our study offers a holistic view of heart failure prognosis. The findings not only reinforce the critical role of established risk factors but also highlight the evolving nature of these risks over time. While the Cox model demonstrates strong discriminative ability, it also suggests the need for refinement in risk predictions and addressing slight over-estimation. Future work will focus on refining the model's complexity, exploring alternative approaches, and conducting external validation to enhance its accuracy and applicability in diverse clinical settings. This study, by identifying significant predictors such as creatinine levels, age, ejection fraction, and blood pressure, contributes to a deeper understanding of heart failure progression and lays the groundwork for more personalized and effective patient management strategies.

\newpage

# References

1. Ahmad, T., Munir, A., Bhatti, S. H., Aftab, M., & Raza, M. A. (2017). Survival analysis of heart failure patients: A case study. PLOS ONE, 12(7), e0181001. https://doi.org/10.1371/journal.pone.0181001

2. Collett, D. (1999). Modelling survival data in medical research. Chapman &amp; Hall/CRC.

3. Heagerty, P. J., & Zheng, Y. (2005). Survival Model Predictive Accuracy and ROC Curves. Biometrics, 61(1), 92105. https://doi.org/10.1111/j.0006-341X.2005.030814.x

4. Jones, N., Ak, R., Adoki, I., Fdr, H., & Cj, T. (2019). Survival of patients with chronic heart failure in the community: a systematic review and metaanalysis. European Journal of Heart Failure, 21(11), 13061325. https://doi.org/10.1002/ejhf.1594

5. Pavlou, M., Ambler, G., Seaman, S. R., Guttmann, O., Elliott, P., King, M., & Omar, R. Z. (2015). How to develop a more accurate risk prediction model when there are few events. BMJ, h3868. https://doi.org/10.1136/bmj.h3868

6. Steyerberg, E. W., & Vergouwe, Y. (2014). Towards better clinical prediction models: Seven steps for development and an ABCD for validation. European Heart Journal, 35(29), 19251931. https://doi.org/10.1093/eurheartj/ehu207


7. Zamora, E., Lupn, J., Urrutia, A., Gonzlez, B., Mas, D., Dez, C., Altimir, S., &amp; Valle, V. (2007, December 1). Prognostic significance of creatinine clearance rate in patients with heart failure and normal serum creatinine: Revista Espaola de Cardiologa. Revista Espaola de Cardiologa (English Edition). https://www.revespcardiol.org/en-prognostic-significance-creatinine-clearance-rate-articulo-13114181 

8. Zhong, J., Gao, J., Luo, J. C., Zheng, J. L., Tu, G. W., & Xue, Y. (2021). Serum creatinine as a predictor of mortality in patients readmitted to the intensive care unit after cardiac surgery: a retrospective cohort study in China. Journal of thoracic disease, 13(3), 17281736. https://doi.org/10.21037/jtd-20-3205

\newpage

# Appendix
## Code

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
